<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->





<title>Xiaoming Li - Homepage</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Xiaoming Li">
<meta property="og:title" content="Xiaoming Li">


  <link rel="canonical" href="http://localhost:4001/">
  <meta property="og:url" content="http://localhost:4001/">



  <meta property="og:description" content="Research Fellow at MMLab@NTU">









<!-- end SEO -->


<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="assets/css/main.css">

<meta http-equiv="cleartype" content="on">
<head>
  <base target="_blank">
</head>
    <link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
<link rel="manifest" href="images/site.webmanifest">

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="#about-me">Homepage</a></li>
          
            <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
          
            <li class="masthead__menu-item"><a href="/#-news">News</a></li>
          
            <li class="masthead__menu-item"><a href="/#-select-publications">Publications</a></li>
          
            <li class="masthead__menu-item"><a href="/#-educations">Educations</a></li>
          
            <li class="masthead__menu-item"><a href="/#-internships">Internships</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div id="main" role="main">
      
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person" class="profile_box">

  <div class="author__avatar">
    <img src="images/photo.png" class="author__avatar" alt="Xiaoming Li <br> ï¼ˆææ™“æ˜ï¼‰">
  </div>

  <div class="author__content">
    <h3 class="author__name">Xiaoming Li <br> ï¼ˆææ™“æ˜ï¼‰</h3>
    <p class="author__bio"></p>
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
    <ul class="author__urls social-icons">
      
        <li><div style="white-space: normal; margin-bottom: 1em;">Research Fellow at MMLab@NTU</div></li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Singapore</li>
      
      
      
      
        <li><a href="mailto:csxmli@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/csxmli2016"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=tmT_voUAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
      
      
    </ul>
      <div class="author__urls_sm">
      
      
        <a href="mailto:csxmli@gmail.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
      
      
       
      
      
      
      
      
      
      
      
      
      
        <a href="https://github.com/csxmli2016"><i class="fab fa-fw fa-github" aria-hidden="true"></i></a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <a href="https://scholar.google.com/citations?user=tmT_voUAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i></a>
      
      
      
      
      
    </div>
  </div>
</div>

  
  </div>

    
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="">
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">
            
<p><span class="anchor" id="about-me"></span></p>

<div style="text-align: justify; line-height: 1.6; margin-bottom: 20px;">

  <p>I am an incoming Associate Professor with <a href="https://prlab-nju.com/nju/">PRLab</a> at <a href="https://is.nju.edu.cn/">the School of Intelligence Science and Technology</a>, Nanjing University (Suzhou Campus).
Currently, I am a research fellow at <a href="https://www.mmlab-ntu.com/" target="_blank">MMLab@NTU</a>, Nanyang Technological University, Singapore, working with Prof. <a href="https://www.mmlab-ntu.com/person/ccloy/" target="_blank">Chen Change Loy</a>.
I obtained my joint Ph.D degrees from Harbin Institute of Technology and The Hong Kong Polytechnic University, under the supervision of Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&amp;user=rUOpCEYAAAAJ&amp;view_op=list_works" target="_blank">Wangmeng Zuo</a> and Prof. <a href="https://www4.comp.polyu.edu.hk/~cslzhang/" target="_blank">Lei Zhang</a>.
My research interests lie in high-fidelity image restoration (face/text) and controllable image generation.</p>
</div>

<div style="background-color: #fff9e6; border: 1px solid #ffe58f; border-radius: 0.5rem; padding: 1.25rem; margin: 1.25rem 0;">
  <h3 style="margin-top: 0; color: #d46b08; font-size: 1.1rem;">
    <i class="fas fa-flag"></i> Openings / æ‹›ç”Ÿä¿¡æ¯
  </h3>
  <hr style="border: 0; border-top: 1px solid #ffe58f; margin: 0.75rem 0;" />
  
  <p style="margin-bottom: 0.75rem; line-height: 1.6;">
    We are <strong>actively looking</strong> for passionate and talented students to join our research group at <strong>Nanjing University (Suzhou)</strong>. If you are interested in working on <strong>image restoration</strong> and <strong>image/video generation/editing</strong>, please send me an email with your CV.
  </p>
  
  <p style="margin-bottom: 0.75rem; line-height: 1.6;">
    æˆ‘ä»¬è¯¾é¢˜ç»„é•¿æœŸæ¬¢è¿æœ‰å¿—äº<strong>å›¾åƒ/è§†é¢‘å¤åŸ/ç¼–è¾‘ã€ç”Ÿæˆæ¨¡å‹</strong>ç­‰æ–¹å‘çš„ä¼˜ç§€åŒå­¦åŠ å…¥ï¼æœ‰æ„å‘çš„åŒå­¦è¯·å‘é€ç®€å†è‡³æˆ‘çš„é‚®ç®±ã€‚
  </p>

  <div style="line-height: 1.6;">
    <p><strong>æ‹›æ”¶å¯¹è±¡</strong></p>
    <ul>
      <li><strong>æœ¬ç§‘ç”Ÿï¼š</strong> å—äº¬å¤§å­¦åŠå…¶ä»–é«˜æ ¡å¤§ä¸€è‡³å¤§ä¸‰å­¦ç”Ÿï¼Œéœ€ä¿è¯è‡³å°‘ä¸€å¹´çš„è¿›ç»„ç§‘ç ”æ—¶é—´æˆ–è€…å®Œæˆä¸€ä¸ªå®Œæ•´å·¥ä½œï¼Œè¡¨ç°ä¼˜ç§€è€…æä¾›ç§‘ç ”è¡¥åŠ©ã€‚</li>
      <li><strong>ç ”ç©¶ç”Ÿï¼š</strong> ç¡•å£«/<del>åšå£«</del>ç ”ç©¶ç”Ÿï¼Œæ¬¢è¿è®¡ç®—æœºã€æ•°å­¦ç­‰ç›¸å…³ä¸“ä¸šèƒŒæ™¯ã€‚</li>
      <li><strong>ç ”ç©¶äººå‘˜ï¼š</strong> å…¨èŒ/å…¼èŒç ”ç©¶åŠ©ç† (RA)ã€‚</li>
    </ul>
  </div>
  <!--
  **2. ç¡•å£«ç ”ç©¶ç”Ÿè¯´æ˜**
  * æ‹›æ”¶å¯¹è±¡ä¸ºæ„¿æ„å…¨èº«å¿ƒæŠ•å…¥åšå¥½ç§‘ç ”ã€å­¦ä¹ ä¸“ä¸šçŸ¥è¯†çš„å­¦ç”Ÿã€‚
  * éœ€å¯¹ç¼–ç¨‹èƒ½åŠ›æœ‰è‡ªä¿¡ï¼Œå–œæ¬¢é˜…è¯»æºç ã€‚
  * å¦‚æˆåŠŸä¿ç ”ï¼Œå»ºè®®å¤§å››åœ¨è¯¾é¢˜ç»„å†…å®Œæˆæ¯•è®¾ï¼Œæå‰ç†Ÿæ‚‰èƒŒæ™¯å¹¶åœ¨å…¥å­¦å‰å°è¯•æŠ•ç¨¿ã€‚
  **3. åšå£«ç ”ç©¶ç”Ÿè¯´æ˜**
  * ä¼˜å…ˆè€ƒè™‘ä»¥ç¬¬ä¸€ä½œè€…èº«ä»½åœ¨ CCF A ç±»ä¼šè®®æˆ–æœŸåˆŠå‘è¡¨è¿‡è‡³å°‘ä¸€ç¯‡è®ºæ–‡çš„åŒå­¦ã€‚
  * å…·æœ‰ç”Ÿæˆå¼å¤§æ¨¡å‹ç›¸å…³ç ”ç©¶ç»éªŒè€…ä¼˜å…ˆè€ƒè™‘ã€‚
  * -->
  <!--<p style="margin-bottom: 0; font-weight: bold;">
    ç›®å‰ï¼Œè¯¾é¢˜ç»„æ­£åœ¨æ‹›æ”¶ <span style="color: #cf1322;">2026å¹´ç§‹å­£</span> å…¥å­¦çš„ç¡•å£«ç ”ç©¶ç”Ÿå’Œåšå£«ç ”ç©¶ç”Ÿã€‚æ¬¢è¿æ„Ÿå…´è¶£çš„åŒå­¦ç§¯ææŠ•é€’ç®€å†ï¼
  </p>-->
</div>

<h1 id="-news">ğŸ”¥ News</h1>

<div style="max-height: 16rem; overflow-y: auto; padding-right: 1rem;">

  <ul>
    <li><em>2025.12</em>: Â  One paper is accepted in IJCV.</li>
    <li><em>2025.11</em>: Â  è·å¾— ä¸­å›½å›¾è±¡å›¾å½¢å­¦å­¦ä¼šè‡ªç„¶ç§‘å­¦äºŒç­‰å¥–ï¼Œæ’å3/5.</li>
  </ul>

</div>

<h1 id="-select-publications">ğŸ“ Select Publications</h1>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">IJCV 2026</div><img src="images/AITTI.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>AITTI: Learning Adaptive Inclusive Token for Text-to-Image Generation</strong></p>

    <p>International Journal of Computer Vision, 2026</p>

    <p>Xinyu Hou, <strong><u>Xiaoming Li</u></strong>, Chen Change Loy</p>

    <p><a href="https://arxiv.org/pdf/2406.12805"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/itsmag11/AITTI"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">AAAI 2026</div><img src="images/refstar.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>RefSTAR: Blind Facial Image Restoration with Reference Selection, Transfer, and Reconstruction</strong></p>

    <p>The Association for the Advancement of Artificial Intelligence, 2026</p>

    <p>Zhicun Yin, Junjie Chen, Ming Liu, Zhixin Wang, Fan Li, Renjing Pei, <strong><u>Xiaoming Li</u></strong>, Rynson WH Lau, Wangmeng Zuo</p>

    <p><a href="https://arxiv.org/pdf/2507.10470"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/yinzhicun/RefSTAR"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">TPAMI 2025</div>
<!--<img src='images/marconetplus.jpg' alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" >-->
<video src="images/marconetplusC.mp4" muted="" autoplay="" loop="" playsinline="" onclick="openModal(this.src)" title="Click to enlarge" style="width: 100%; cursor:zoom-in;"></video>
</div></div>
<div class="paper-box-text">

    <p><strong>Enhanced Generative Structure Prior for Chinese Text Image Super-Resolution</strong></p>

    <p>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2025</p>

    <p><strong><u>Xiaoming Li</u></strong>, Wangmeng Zuo, Chen Change Loy</p>

    <p><a href="https://arxiv.org/pdf/2508.07537"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/csxmli2016/MARCONetPlusPlus"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ICCV 2025</div><img src="images/omegance_demo.gif" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Omegance: A Single Parameter for Various Granularities in Diffusion-Based Synthesis</strong></p>

    <p>International Conference on Computer Vision, 2025</p>

    <p>Xinyu Hou, Zongsheng Yue, <strong><u>Xiaoming Li</u></strong>, Chen Change Loy</p>

    <p><a href="https://openaccess.thecvf.com/content/ICCV2025/papers/Hou_Omegance_A_Single_Parameter_for_Various_Granularities_in_Diffusion-Based_Synthesis_ICCV_2025_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/itsmag11/Omegance"><i class="fab fa-github"></i> <strong>Code</strong></a> Â Â Â 
<a href="https://itsmag11.github.io/Omegance/"><i class="fas fa-home"></i> <strong>Project Page</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">CVPR 2024</div><img src="images/wplus.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>When stylegan meets stable diffusion: a w+ adapter for personalized image generation</strong></p>

    <p>IEEE International Conference on Computer Vision and Pattern Recognition, 2024</p>

    <p><strong><u>Xiaoming Li</u></strong>, Xinyu Hou, Chen Change Loy</p>

    <p><a href="http://openaccess.thecvf.com/content/CVPR2024/papers/Li_When_StyleGAN_Meets_Stable_Diffusion_a_W_Adapter_for_Personalized_CVPR_2024_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/csxmli2016/w-plus-adapter"><i class="fab fa-github"></i> <strong>Code</strong></a> Â Â Â 
<a href="https://csxmli2016.github.io/projects/w-plus-adapter/"><i class="fab fa-home"></i> <strong>Project Page</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ECCV 2024</div><img src="images/wideangle.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Combining Generative and Geometry Priors for Wide-Angle Portrait Correctionn</strong></p>

    <p>European Conference on Computer Vision, 2024</p>

    <p>Lan Yao, Chaofeng Chen, <strong><u>Xiaoming Li</u></strong><sup><i class="fas fa-envelope" style="vertical-align: baseline;" title="Corresponding author"></i></sup>, Zifei Yan, Wangmeng Zuo</p>

    <p><a href="https://arxiv.org/pdf/2410.09911"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/Dev-Mrha/DualPriorsCorrection"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">TPAMI 2023</div><img src="images/dmdnet.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Learning Dual Memory Dictionaries for Blind Face Restoration</strong></p>

    <p>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023</p>

    <p><strong><u>Xiaoming Li</u></strong>, Shiguang Zhang, Shangchen Zhou, Lei Zhang, Wangmeng Zuo</p>

    <p><a href="https://arxiv.org/pdf/2210.08160"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/csxmli2016/DMDNet"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">CVPR 2023</div><img src="images/marconet.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Learning Generative Structure Prior for Blind Text Image Super-resolution</strong></p>

    <p>IEEE International Conference on Computer Vision and Pattern Recognition, 2023</p>

    <p><strong><u>Xiaoming Li</u></strong>, Wangmeng Zuo, Chen Change Loy</p>

    <p><a href="http://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_Generative_Structure_Prior_for_Blind_Text_Image_Super-Resolution_CVPR_2023_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/csxmli2016/MARCONet"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ECCV 2022</div><img src="images/f2n.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>From Face to Natural Image: Learning Real Degradation for Blind Image Super-Resolution</strong></p>

    <p>European Conference on Computer Vision, 2022</p>

    <p><strong><u>Xiaoming Li</u></strong>, Chaofeng Chen, Xianhui Lin, Wangmeng Zuo, Lei Zhang</p>

    <p><a href="https://arxiv.org/pdf/2210.00752"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/csxmli2016/ReDegNet"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">CVPR 2022</div><img src="images/SAFM.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Semantic-shape Adaptive Feature Modulation for Semantic Image Synthesis</strong></p>

    <p>IEEE International Conference on Computer Vision and Pattern Recognition, 2022</p>

    <p>Zhengyao Lv, <strong><u>Xiaoming Li</u></strong>, Zhenxing Niu, Bing Cao, Wangmeng Zuo</p>

    <p><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Lv_Semantic-Shape_Adaptive_Feature_Modulation_for_Semantic_Image_Synthesis_CVPR_2022_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/cszy98/SAFM"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">CVPR 2021</div><img src="images/psfrgan.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Progressive semantic-aware style transformation for blind face restoration</strong></p>

    <p>IEEE International Conference on Computer Vision and Pattern Recognition, 2021</p>

    <p>Chaofeng Chen, <strong><u>Xiaoming Li</u></strong>, Lingbo Yang, Xianhui Lin, Lei Zhang, Kwan-Yee K Wong</p>

    <p><a href="http://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Progressive_Semantic-Aware_Style_Transformation_for_Blind_Face_Restoration_CVPR_2021_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/chaofengc/PSFRGAN"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">CVPR 2021</div><img src="images/sean.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Learning Semantic Person Image Generation by Region-Adaptive Normalization</strong></p>

    <p>IEEE International Conference on Computer Vision and Pattern Recognition, 2021</p>

    <p>Zhengyao Lv, <strong><u>Xiaoming Li</u></strong>, Xin Li, Fu Li, Tianwei Lin, Dongliang He, Wangmeng Zuo</p>

    <p><a href="http://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Learning_Semantic_Person_Image_Generation_by_Region-Adaptive_Normalization_CVPR_2021_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/cszy98/SPGNet"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ECCV 2020</div><img src="images/dfdnet.gif" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Blind Face Restoration via Deep Multi-scale Component Dictionaries</strong></p>

    <p>European Conference on Computer Vision, 2020</p>

    <p><strong><u>Xiaoming Li</u></strong>, Chaofeng Chen, Shangchen Zhou, Xianhui Lin, Wangmeng Zuo, Lei Zhang</p>

    <p><a href="https://arxiv.org/pdf/2008.00418"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/csxmli2016/DFDNet"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">CVPR 2020</div>
<video src="images/asffnet.mp4" width="100%" muted="" autoplay="" loop="" playsinline="" onclick="openModal(this.src)" title="Click to enlarge" style="cursor:zoom-in;"></video>
</div></div>
<div class="paper-box-text">

    <p><strong>Enhanced Blind Face Restoration With Multi-Exemplar Images and Adaptive Spatial Feature Fusion</strong></p>

    <p>IEEE International Conference on Computer Vision and Pattern Recognition, 2020</p>

    <p><strong><u>Xiaoming Li</u></strong>, Wenyu Li, Dongwei Ren, Hongzhi Zhang, Meng Wang, Wangmeng Zuo</p>

    <p><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Enhanced_Blind_Face_Restoration_With_Multi-Exemplar_Images_and_Adaptive_Spatial_CVPR_2020_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/csxmli2016/ASFFNet512"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ECCV 2018</div><img src="images/gfrnet.jpg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Learning Warped Guidance for Blind Face Restoration</strong></p>

    <p>European Conference on Computer Vision, 2018</p>

    <p><strong><u>Xiaoming Li</u></strong>, Ming Liu, Yuting Ye, Wangmeng Zuo, Liang Lin, Ruigang Yang</p>

    <p><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiaoming_Li_Learning_Warped_Guidance_ECCV_2018_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/csxmli2016/GFRNet"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<div class="paper-box"><div class="paper-box-image"><div><div class="badge">ECCV 2018</div><img src="images/shiftnet.jpeg" alt="sym" width="100%" style="cursor: pointer;" onclick="openModal(this.src)" title="Click to enlarge" /></div></div>
<div class="paper-box-text">

    <p><strong>Shift-Net: Image Inpainting via Deep Feature Rearrangement</strong></p>

    <p>European Conference on Computer Vision, 2018</p>

    <p>Zhaoyi Yan, <strong><u>Xiaoming Li</u></strong>, Mu Li, Wangmeng Zuo, Shiguang Shan</p>

    <p><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Zhaoyi_Yan_Shift-Net_Image_Inpainting_ECCV_2018_paper.pdf"><i class="fas fa-file-pdf"></i> <strong>PDF</strong></a> Â Â Â 
<a href="https://github.com/Zhaoyi-Yan/Shift-Net"><i class="fab fa-github"></i> <strong>Code</strong></a></p>

  </div>
</div>

<!--
# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
-->

<h1 id="-educations">ğŸ“– Educations</h1>
<ul>
  <li><em>2019.01 - 2022.09</em>, The Hong Kong Polytechnic University, Joint PhD, Suprevisor: <a href="https://www4.comp.polyu.edu.hk/~cslzhang/">Prof. Lei Zhang</a>.</li>
  <li><em>2016.09 - 2021.09</em>, Harbin Institute of Technology, PhD, Supervisor: <a href="https://scholar.google.com/citations?user=rUOpCEYAAAAJ">Prof. Wangmeng Zuo</a>.</li>
  <li><em>2013.09 - 2016.07</em>, Harbin Institute of Technology, Master.</li>
  <li><em>2009.09 - 2013.07</em>, Harbin Institute of Technology, Bachelor.</li>
</ul>

<!--
# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)
- -->

<h1 id="-internships">ğŸ’» Internships</h1>
<ul>
  <li><em>2019.11 - 2021.11</em>, <a href="https://damo.alibaba.com/">Alibaba DAMO Academy</a>.</li>
</ul>

<hr />
<p style="text-align: center; color: #888; font-size: 1rem; margin-top: 0.5rem;">
The website template is adapted from <a href="https://github.com/RayeRen/rayeren.github.io" target="_blank" style="color: #777; text-decoration: underline;">RayeRen</a>.
Last updated: January 2, 2026
</p>

<!-- 
############################################################################################################################################
å®šä¹‰scriptçš„function
############################################################################################################################################
-->

<div id="myModal" onclick="closeModal()" style="display:none; position:fixed; z-index:9999; top:0; left:0; width:100%; height:100%; background-color:rgba(0,0,0,0.9); cursor:zoom-out;">
  <div id="modalContent" style="margin:auto; display:block; max-width:90%; max-height:90%; position:relative; top:50%; transform:translateY(-50%); text-align:center;">
  </div>
</div>

<p><a href="https://clustrmaps.com/site/1bd1m" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=QOUn4w5djX3sOmVRx_qPmV2YK0mxkbPUBhLlp8-cTH4&amp;cl=ffffff" style="display: none;" /></a></p>

          </section>
        </div>
      </article>
    </div>

    <script src="assets/js/main.min.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "");
</script>


<script>
    $(document).ready(function () {
        
        var gsDataBaseUrl = 'https://cdn.jsdelivr.net/gh/csxmli2016/csxmli2016.github.io@'
        
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {
            var totalCitation = data['citedby']
            document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = '| Citations: ' + numCitations;
            });
        });
    })
</script>


  </body>
</html>
